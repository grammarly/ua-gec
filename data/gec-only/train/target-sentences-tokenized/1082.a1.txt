Що таке інтелект ?
Щоб створити штучний інтелект , спершу треба зрозуміти , що ж таке інтелект .
На жаль , ще досі немає чіткого визначення .
Хтось скаже , що це якось пов’язано з пам’яттю , як людина вирішує задачі , що це проявляється в тому , як людина говорить або як не говорить , і як поводиться .
Уявлення розмите .
Так само у вікіпедії написано “ багато слів ” .
Серед науковців так само немає згоди , що слід розуміти під інтелектом , хоча є визначення , яке підтримує більшість :
Інтелект — це здатність досягати цілі в різних середовищах .
Коротко і просто .
Але кожне слово підібране дуже ретельно .
Розберемо кожне слово .
Перше , інтелект — це здатність , чи , може , шмат матерії “ досягати цілі в різних середовищах ” .
Усі живі істоти досягають цілі і тому , за визначенням , мають інтелект , але в кожного він різний , це кількісна величина .
Кидаєш коту їсти , а він не бачить і не чує , і думаєш : “ оце тупий кіт , собака зразу б з’їв ” .
Наступне слово — середовище .
Воно найскладніше , я так до кінця й не зрозумів , що це таке .
Наприклад , для програми , що грає в шахи , шахи і є середовищем .
8 на 8 клітинок , по 16 фігур по краях , кожна фігура по своєму ходить .
Чим більшими і сильнішими є фігури , тим краще , але доля короля визначає все .
У шахах близько 10⁵⁰ можливих дощок ( те , як можуть стояти фігури ) , і ще більше можливих варіантів зіграти гру ( оцінка десь 10¹²⁰ ) .
Написати програму , щоб вигравала просто перебором варіантів , неможливо , фізично неможливо .
У всесвіті атомів навіть менше , десь 10⁸⁰ .
Ніколи такого комп’ютера , яким би він квантовим не був , ми не збудуємо .
І коли вперше програма виграла в найкращого гравця ( DeepBlue проти Каспарова в 1997 р . ) всі сказали « Вау ! » .
Те ж саме було недавно , коли програма виграла в гру го , вже інше середовище зі своїми правилами , яке значно складніше за шахи ( 10¹⁷⁰ дощок ) .
За останні роки з’явилося багато прикладів , де програма в межах свого середовища показує вражаючі результати .
Одна програма вміє розпізнавати зображення , інша — давати рекомендації в ютубі , ще інша — перекладати текст .
Але в кожному випадку це тільки одне вузьке середовище .
Якщо навіть трохи змінити правила шахів , скажімо , “ кінь ходить двічі ” , то найкраща в світі програма ламається .
Вона не адаптується до нового середовища , як це роблять тварини чи люди .
Розробники знають про ці обмеження і стараються зробити , щоб програма могла робити все ( MuZero , мабуть , найкраще що зараз є ) .
Але поки не вдається .
Саме через це вставили у визначення слово « різних » .
Одна і та сама програма має вигравати в шахи , їздити на машині , перекладати текст , готувати макарони …
Чим в більшій кількості середовищ вона може працювати , тим краще .
Хоча насправді існує тільки одне справжнє середовище .
Об’єктивна реальність , яку ми називаємо всесвітом .
Що важливо , це інформація , яку ми отримуємо ( через сенсори ) і як можемо взаємодіяти з середовищем ( рухатися ) .
Кількість інформації , що отримують тварини в морі чи на суші , навіть найпростіші , значно більша , ніж у шахах чи го .
Для прикладу , запустимо в якесь болотце робота з простенькою камерою в 1 мегапіксель ( 1000 на 1000 ) та ще й чорно - білою ( 8 бітів на піксель , 2⁸ =256 градацій сірого ) .
Пікселі на камері можуть прийняти 256 в степені 1000х1000 можливих значень .
Це набагато більше ніж 10¹⁷⁰ .
В залежності від значення пікселів треба прийняти рішення , як рухатися , куди йти .
І запам’ятати , де була їжа чи небезпека .
Нехай камера знімає 10 кадрів за секунду .
Якщо тупо записувати інформацію про середовище , нам треба зберігати кожну секунду в десяти мегабайтах пам’яті .
За день вийде під терабайт .
Але якщо записувати з розумом , то вийде значно менше .
Чому так ?
Бо наш всесвіт такий класний , що заклав у своїй основі можливість стиснення інформації , абстрактні закони , які тварини через еволюцію знайшли і реалізували .
І тепер ми дивимося на тварин і стараємося здогадатися , що ж це за закони .
Частину ми відкрили , так з’явилася теорія інформації 80 років тому .
Саме завдяки їй ми стискаємо зображення в джіпег , музику в мп3 і можемо добре заархівувати текст .
Тоді й ввели фундаментальне поняття для інформації — ентропія , яка показує як сильно ми можемо стиснути дані .
Візьмімо для прикладу послідовність , яку треба зберегти ( чи передати ) .
Ця послідовність випадкова , ентропія велика ( звідси часто кажуть , що це міра хаосу ) і доведеться зберігати все як є .
Але візьмімо іншу послідовність :
Вона поцікавіша , ентропія менша , значить можна стиснути .
Ми помічаємо , що тут є речі , які повторюються , наприклад , 0101010 , 01110 .
Їх називають ще патернами ? чи регулярностями .
Можна виділити патерни , присвоїти їм нові cимволи та зберегти послідовність коротше .
Ось ми і стиснули дані .
В цьому прикладі стиснення просте , сучасні алгоритми роблять це значно краще , на межі теоретичної можливості , витискають з природи все .
Якби рядок змінювався в часі , то так само можна було б виділити патерни в часі і стиснути відео .
Як виявляється , наше середовище містить купу таких патернів , те , що повторюється , має залежності , причинно - наслідкові зв’язки .
В шахах не всі ходи однакові , експерт інтуїтивно знає , які позиції кращі , вміє визначати приховані патерни і не перебирати тупо ходи .
І мозок постійно намагається виділити патерни , навіть якщо дати йому випадкову послідовність .
Він усе одно будемо старатиметься якось внести порядок у хаос .
Мозок підлаштовується під середовище і по мозку можна взнати , в якому середовищі він зростав .
Наприклад , в людини є візуальна ілюзія , вертикальні лінії здаються довшими , ніж горизонтальні , хоча по довжині вони однакові .
Вважається , це через те , що в світі більше вертикальних ліній ( границь об’єктів , наприклад ) .
Це дійсно так , фотографували і порахували .
Мозок бачить більше вертикальних ліній і підлаштовується .
Патерни виникають із самих законів світу .
Предмети локальні , бо вони з’єднуються електрикою .
Живі створіння часто симетричні , бо це обчислювально спрощує їхнє кодування в ДНК .
Діти вже в рік дивуються , коли м’яч котиться зі столу і не падає .
Вони ще не говорять , а вже мають уявлення про базові фізичні закони .
Ці патерни про середовище формують те , що зветься моделлю середовища .
В кожного вона є .
Ми знаємо , де що лежить , як виглядають і називаються різні речі , як пройти з роботи додому .
Ми вивчаємо причинно - наслідкові зв’язки , як змінюється середовище само по собі чи через нас .
Усе падає вниз , розетки небезпечні …
Як ніби в голові є комірки з питаннями “ що , де , чому , коли , навіщо , як ” і ми поступово їх заповнюємо .
І в нашому уявлені про світ все зв’язано , я назву слово і до нього виникає багато асоціацій .
В нашій уяві живе груба копія цього світу і ми можемо в уяві крутити нею як хочемо .
Важливо , що модель не намагається максимально зберегти інформацію про середовище , а зберегти рівно на стільки , скільки треба для виживання і розмноження .
Для формування хорошої моделі треба багато часу ( обчислень ) , тому часто мозок робить спрощення , що називається евристиками .
Наприклад , « як він гарно говорить і посміхається , мабуть буде хорошим політиком » )).
І через це є те , що називається когнітивними ілюзіями , коли мозок може сприймати світ не таким , як він є насправді і приймати швидкі рішення , які не завжди найкращі .
Вже розробили багато методів , як підловити мозок на лінощах і халтурі і поправити модель , зробити модель ближчою до середовища , карту більш схожою до території .
Кому цікаво , цим займається теорія раціональності і можна прочитати в книзі Канемана .
На жаль , розмір та швидкість моделі обмежені мозком .
Півтора літра .
У залізяку ж сунь транзисторів скільки хочеш .
І тому науковцям дуже б хотілося , щоб і машина вміла будувати модель середовища , яка буде значно краща за людську .
Визначенням патернів в даних займається підрозділ у машинному навчанні — навчання без учителя ( цим також займається статистика або data science ) .
Бо вчитель не обов’язковий , модель світу є навіть у тварин .
Навчання без учителя , яке має будувати причинно - наслідкову модель середовища , називають « темною матерією машинного навчання » .
Всі розуміють , що це важливо , але не ясно , як зробити .
Одна з основних проблем — це представлення знань .
Як у цій моделі буде записана інформація .
Це питання вже десятки років не вирішене .
Те , як ми записуємо інформацію в комп’ютерах , не підходить , бо це буде як IBM Ватсон чи робот Софія .
Ходячі енциклопедії , але без розуміння .
Я деякий час думав , що нейронні мережі формують модель , зберігаючи розподіл імовірностей , бо в ньому можна зберегти всю інформацію і стиснути добре .
Багато хто і досі так думає і , мабуть , у певних ділянках мозку це таки правда .
Але є щось глибше …
Вище я збрехав , перша послідовність , яку важко було стиснути , насправді не випадкова .
Ну , формально випадкова , всі тести на випадковість це підтвердять .
Але насправді це число Пі =3 , 14159 … , тільки записане в бінарному вигляді ( перші 128 бітів ) .
А ми знаємо багато формул , що генерують число Пі .
Виходить , що можна зберегти не самі дані , а програму , що їх генерує .
І це буде коротше .
Вперше на це звернув увагу Колмогоров ( насправді Соломонофф , див . [ 1 ] ) , який ввів поняття складності .
Складність даних це довжина мінімальної програми , що генерує ці дані .
Це навіть краще за ентропію .
Я думаю , цим мозок і займається , шукає програми , що максимально коротко пояснюють цей світ .
Я б хотів , щоб так було , бо це теоретично найкращий відомий спосіб стиснути дані .
І я б розчарувався якби за мільйони років еволюція його не знайшла .
Невідомо , чи дійсно і як такі програми утворюються в мозку .
Людина збирає інформацію , набиває мозок фактами , аж поки не приходить розуміння .
Коли щось зрозумів , відбувається спрощення , стиснення , менше потрібно нейронів для збереження .
Це економить енергію , це приносить задоволення і рішення часто дає відчуття краси , коли воно просте й елегантне .
В результаті , через поки невідомі процеси , дані компактно збережені в зв’язках та активності нейронів .
До речі , цим також займається фізика , пошуком програм ( їх називають зазвичай законами ) , що описують світ .
Наприклад , рух планет по нічному небі .
Одна з перших програм імені Птолемея пояснювала дані через складний рух по епіциклах .
Це було не точно і занадто складно .
Наступна програма імені Ньютона ввела всесвітнє тяжіння , яке описує рух планет по еліптичних орбітах навколо сонця .
І остання відома , імені Ейнштейна , яка виправила неточність попередньої програми в русі Меркурія .
Що важливо — програма не тільки пояснює дані , але й передбачає майбутнє .
Розташування планет і затемнення вже всі розписані .
Також робити передбачення — це ключова здатність мозку .
Ми уявляємо , яке буде середовище , і якщо картинка така , як нам хочеться , — все ок .
Тут підходимо до передостаннього слова з визначення — “ досягати ” .
Як тільки модель є , то досягти цілі не дуже складно .
Перебираємо свої можливі дії , модель генерує майбутнє , вибираємо найкраще і діємо .
Чим більше і швидше дій можеш перебрати , тим кращу дію вибереш .
Із цим пов’язана свідомість , яка також , як і інтелект , кількісна .
Чим більшої кількості можливих дій ти свідомий , тим ймовірніше , що серед них є саме та .
А з цим пов’язана свобода волі , якщо свідомий тільки однієї дії , то свободи волі ніби й немає .
Звісно , це велике спрощення і варто написати окремо .
Колода можливих дій може йти в комплекті з тілом ( генетично , як у простих тварин ) , можуть додаватися з досвідом ( через спроби і помилки ) , або найбільш просунутий спосіб , через імітацію ( повторити за кимось ) .
Часто такий перебір дій робить підсвідомість .
Головне — сформулювати правильно питання .
Це ж просто магія якась , ти нічого не робиш , а потім — бац і в свідомості з’являється дуже непогане рішення .
Це відбувається навіть уві сні .
Мабуть , тому , часто зранку стає ясно , що робити .
Для прийняття рішень ключовою є модель , бажано з великою пам’яттю та швидкістю .
Але побудова моделі і прийняття рішень пов’язані .
В людини модель будується динамічно через взаємодію з середовищем ( називається action perception loop ) .
Загадайте дітей , які все чіпають , лазять де попало і воду п’ють з калюжі ) .
І останнє , найважливіше слово у визначені — “ ціль ” .
Звідки вона взагалі береться ?
Для машини просто , те що людина накаже , те й робить .
Для тварини цілі визначаються потребами .
Від найпростіших — їжа , безпека , до складніших — соціалізація та самореалізація в людей .
Потреба визначає нашу поведінку і цілі , а ціль визначає сенс існування .
Але які потреби в машини ?
Підзарядитися ?
Чи зможуть колись ці потреби виникнути самі , наприклад , знищити землю ?
Чи зможе машина знайти свій сенс існування ?
Що казати про роботів , людині самій часто важко визначити свої справжні цілі .
З простими , там , поїсти , поспати не важко .
Але складніші можуть сильно викривлятися або просто бути непроявленими чи подавленими .
На жаль , є чимало людей , які зациклені на інтелекті .
Вони думають , що потрібно бути розумним , щоб бути успішним , закінчити сильний університет , щоб отримати топ роботу , заробити багато грошей , щоб задовольнити всі свої потреби .
Раціональне мислення ставлять на перше місце .
Я не применшую його значення , науково - технічний прогрес від нього залежить , але для людини інтелект не найважливіше .
Читай визначення .
Інтелект — це здатність досягати цілі в різних середовищах .
Для людини найважливіше визначити свої цілі , а потім уже їх досягати .
Бо який сенс у сильному інтелекті , якщо ти досягаєш не своїх , а чужих , нав’язаних чи просто помилкових цілей .
Але якщо цілі ріднесенькі , то інтелект ой як стане в нагоді .
І якщо цілі супер складні , наприклад , колонізувати всесвіт , то треба супер інтелект .
І без машин тут не обійтись .
