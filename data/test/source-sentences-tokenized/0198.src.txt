« Китайська Кімната » – в’язниця для роботів
Із стрімким розвитком у галузі штучного інтелекту та реальними перспективами взаємодії з ним у багатьох царинах повсякденного життя , справедливо постають питання про те , як варто себе з ним поводити .
Ці питання простягаються далеко за межі практичного та сягають морально - філософських проблем , що постають перед нами , коли ми уявляємо собі предмет , який поводиться ніби він живий .
Багато хто вже ставиться до роботів як до живих істот , а дехто згадує славнозвісний тест Тюринґа , коли роботу можна приписувати людську свідомість , якщо після спілкування з ним складеться враження , ніби він людина .
Але питання визначення такої свідомості насправді дуже складне і вже більш як пів століття викликає запеклі суперечки .
Аби продемонструвати , що про зміст не завжди можна судити за формою , я розповім про так звану Проблему Китайської Кімнати .
Вона була сформована у 1980 році американським філософом Джоном Роджерсом Серлом ( John Rogers Searle ) і вийшла вона статею „ Minds , Brains , and Programs “ у журналі „ The Behavioral and Brain Sciences “ .
Палкі дискусії почалися ще перед виходом статті , тож у її остаточній версії автор опублікував відповіді на найважливішу критику .
Та можливі відповіді на цю Проблему публікують і досі .
Формулюючи суть , я залишив за собою свободу переформулювати умови задачі так , аби вони були зрозумілі сучасному читачеві .
Уявіть , що Вас взяли на роботу як секретаря , замкнули у кімнаті , заповненій книгами , та наказали Вам вести переписку з клієнтами .
Звучить як типовий робочий день в офісі , еге -ж ?
Але є одна проблема .
Ваші клієнти спілкуються мовою , яку ви ніколи не вчили і не розумієте .
Джон Серл , не розумів китайської , і вів оповідання від своєї особи – звідти назва мисленого експерименту .
Ваш робочий процес виглядає так : Ви отримуєте записку чи повідомлення , яке написано ієрогліфами та маєте на нього відповісти .
Щоб це зробити , Вам на допомогу приходять книги , якими обставлена кімната – вони виявляються довідниками з інструкцій .
Ви шукаєте комбінацію ієрогліфів з повідомлення у довіднику та дивитеся , які ієрогліфи потрібно написати у відповідь .
І ось – Ваш клієнт отримав те , про що питав , і йде задоволений .
Можливо , він спитав Вас , який ваш улюблений колір , можливо – про атомну масу диспрозію – ви цього не дізнаєтеся , бо не розумієте його мови .
Але для клієнта це виглядатиме так , ніби він говорить з людиною , яка якщо й не розбирається в поставлених питаннях , то хоча б розмовляє китайською .
У нього є всі підстави вважати , що якщо щось виглядає як качка та крякає – це є качка .
З точки зору програмування штучного інтелекту , питання клієнта – це інструкція , а Ваша відповідь – це реакція ШІ на інструкцію .
Довідники , що ними заповнена кімната , можуть бути видані начальством – тоді ми кажемо , що ШІ *запрограмовано* згори , а може бути , що Ви самі їх заповнюєте , коли спілкуєтеся з клієнтом .
В такому разі , клієнт , наприклад , має поставити оцінку реалістичності Вашої відповіді .
Поспілкувавшись кілька мільйонів разів , Ви ( чи Ваш відділ – роботу , дяка Богу , можна розділити ) зможете записати у довідники відповіді , за які було отримано найвищий бал ; але робитимете Ви це навмання , випадково підбираючи варіанти .
Це називається *машинним навчанням* .
Як бачите , усі ці процеси – це лише реакція на зовнішні команди , а розуміння мови для цього не є потрібним .
Аби впевнитися , що стелажі зі словниками самі не мають розуміння мови ( аргумент про системність ) , Ви можете зазубрити усі відповіді з усіх книжок напам’ять – та відповідати самотужки .
Ви все ще не розумієте китайської та все ще виглядаєте так , ніби розумієте .
Такий принцип можна відтворити у будь-чому .
« Паперова машина Тюринґа » - це набір інструкцій для гри у шахи , де написано , який хід треба робити у випадку будь-якої певної розстановки фігур на дошці .
Той , хто читає цю інструкцію , не повинен вміти грати в шахи .
Можливо навіть збудувати штучний інтелект , який може сам навчитися грати у хрестики - нулики , маючи сотню сірникових коробок та кількасот жетонів різного кольору .
Про нього я , можливо , ще розповім .
Але принцип в усіх цих випадках один і той самий , і за ним виконання дій не означає їхнього розуміння .
Наразі , ми маємо роботів Boston Dynamics , які ще вчаться ходити та взаємодіяти з навколишніми предметами .
Маємо ми і робота Софію , яка вміє слухати та говорити , зчитувати та показувати емоції .
Але варто розуміти , що людську поведінку можна імітувати , не будучи людиною та не маючи самосвідомості , і це все-одно виглядатиме справжнім .
Сучасні технології взагалі добре опанували імітацію .
Головна різниця між людиною та машиною , яку треба зазначити на цьому етапі – це те , що людина може покинути китайську кімнату та вивчити мову будь-яким відомим методом .
Штучний інтелект не може вийти з кімнати – все , що поступає до нього , переводиться у двійковий код – його « ієрогліфи » , і лише ними він « бачить » світ .
Ознака , яку має інтелект людини чи інших тварин натомість , зветься розумним словом інтенціональність .
Воно означає , що розумова діяльність істоти направлена на щось та має певну ціль .
Інтенціональність , як то можна сказати , обумовлена конструкційно .
Найпростіше її зрозуміти , поглянувши на найпростіші емоції на кшталт голоду та страху .
Нервова система тварин збудована так , аби розуміти небезпеку – ба , навіть проста жива клітина , яка насправді є мініатюрним комп’ютером , також має таке розуміння .
Воно зумовлене наявністю певного стану рівноваги клітини чи нервової системи , якого ці системи завжди прагнуть .
Все , що людина сприймає , як ззовні , так і зсередини , порушує такий стан рівноваги , і реакції людини напрямлені на те , аби цей стан коли - небудь віднайти .
Це й навчило людину *розуміти* .
Людина розуміє китайську , бо має з цього якийсь зиск – від виживання в Китаї до задоволення спілкуватися з друзями з Шанхаю .
Китайська кімната всього - лише запрограмована відповідати на запити .
Своєї інтенціональності , свого зиску вона не має , а зовнішні запити не збурюють її внутрішній стан .
Іншими словами , як би Ви не відповідали клієнтам , Вашу заробітну плату не змінять – треба лише відповідати за інструкціями .
Тому передчасним є приписувати штучним інтелектам будь-який вид людської свідомості лише на базі того , що вони успішно склали тест Тюринґа .
Звісно , людям притаманно приписувати людську сутність усьому , що виглядає як людина та поводить себе антропоморфно – це вже програма , закладена у наш мозок , і це непомітно для нас допомагає нам у соціалізації .
Але одвічні питання наукової фантастики стосовно того , як люди повинні поводити себе з синтетичним життям , ще мають багато часу для опрацювання , бо до створення справжніх штучних істот буде ще багато складної та кропіткої роботи – і це ще якщо людство вирішить обрати цей шлях та не відступитися від нього .
Якщо роботів з інтенціональністю створити й можна – окрім наукових дослідів важко уявити собі від них практичну користь , яку б не мали до того часу вже звичайні безвольні штучні інтелекти .
Та навіть коли таке життя створити , його не варто поспішати оцінювати відомими категоріями .
Багато хто бачив « знущання над роботами » під час тестів у Boston Dynamics , і багато кому певно було шкода тих роботів , яким робили боляче .
Так от – роботам все одно , і їм точно не боляче , бо для них не побудували нервової системи , яка б передавала біль чи фрустрацію .
Настільки очевидно – але все одно доводиться говорити вголос .
Більшість очікувань та страхів перед ШІ – це наші власні людські проєкції .
Тож , можливо , у недалекому майбутньому роботи й захоплять світ , якщо їх запрограмувати чи навчити , але вони навряд чи розумітимуть , для чого їм все це .
Боятися треба не машин , а тих , хто ними користується .
~by Ivort ===== [ 1 ] Searle J . Minds , Brains , and Programs .
The Philosophy of Artificial Intelligence / Boden M ( ed . ) Oxford .
1990 .
Вперше опубліковано в журналі : « The Behavioral and Brain Sciences » , 1980 , № 3 , pp . 417 – 424 . [ 2 ] M . Kaku ( 2008 ) .
Physics of the Impossible : A Scientific Exploration Into the World of Phasers , Force Fields , Teleportation , and Time Travel .
Doubleday .
ISBN 978 - 0 - 385 - 52069 - 0 .
Part I ; 7 . [ 3 ] R . Dawkins ( 1976 ) .
The Selfish Gene .
Oxford University Press .
ISBN 0 - 19 - 857519 - X . [ 4 ] Выход из « Китайской комнаты » или может ли машина думать .
Допис користувача IvanBannikov на https://habr.com/ru/post/405941/