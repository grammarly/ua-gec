Брехня — нова правда. Що таке діпфейки та як їх розпізнати?

Зараз можна легко створити ролик, де Білл Гейтс з іншими рептилоїдами знищує людство своїми вакцинами. Якість не доведеться спотворювати. Чужий голос не треба накладати. Все це зробить машина, та ще й так, що далеко не кожен ідентифікує підробку.

Розказуємо, що таке глибинні фейки та як їх розпізнати в межах підготовки до виставки про персональні дані, кібербезпеку та медіаграмотність Data CTRL Centre. На виставці можна побачити твори українських і світових митців, які працюють із технологіями штучного інтелекту, доповненої реальності, розпізнавання обличчя та іншими цифровими інструментами.

Deep learning + fakes = deepfakes

Діпфейком називають відеопідробку, де одну людину замінюють іншою. Над цим завданням працює комп’ютерна програма, здатна відтворити обличчя на основі аналізу багатьох фотографій людини. Відтворене обличчя накладають на відео, неначе цифрову маску. Розберімося детальніше, як працює технологія і як навчитися її розпізнавати.

Технологія стала можливою завдяки глибинному навчанню: комп’ютери вчаться, використовуючи штучні нейронні мережі. Беремо глибинне навчання, додаємо до нього жагу до створення підробок і отримуємо цілу методику для синтезу зображення. Вся вона базується на штучному інтелекті. З її допомогою навіть найсерйозніші люди роблять у відео різні чудернацькі речі.

Нейронні мережі стають дедалі крутішими. Щоб вони продемонстрували свою роботу в усій красі, потрібні величезні обчислювальні потужності. Нейромережу треба «нагодувати» великим масивом даних, щоб зображення було якомога реалістичнішим.

Брехня — нова правда

Ще у 2018 році світ побачив, як «Барак Обама» називає Трампа гівнюком. Насправді під маскою Обами був американський режисер Джордан Піл. Ролик створили за допомогою програми Fakeapp і графічного редактора Adobe After Effects.

Ось ще одне відео з рубрики «задля забави». Актор Білл Гейдер спародіював Арнольда Шварценеггера, а потім на його обличчя наклали маску актора. Якщо уважно придивитися, стає помітно, що коли Гейдер проводить пальцем перед обличчям, він ніби зникає за маскою. Різниця в чіткості та куті, під яким розміщено палець, вказує на намагання автора діпфейку приховати цей недолік під час обробки відео.

Натренувати око
Розпізнати діпфейк можна, якщо звертати увагу на такі моменти:

Невідповідність кольору шкіри. Часом на відео видно різницю між тоном шкіри маски і решти обличчя. Воно немов покрите шаром різних кольорів із плямами чи краями.
Видимі краї маски навколо обличчя. І різкі, і розмиті.
Оклюзія обличчя. Коли предмети проходять перед обличчям, маска спотворює або закриває предмет.
Розмите обличчя. Різниця в різкості або роздільній здатності між маскою та рештою відео.
Ефект мерехтіння. Коли алгоритм не може розпізнати обличчя і на мить припиняє створювати маску, зображення мерехтить.
Неправильна перспектива. Або різна фокусна відстань.
Краї профілю. Профіль обличчя видається неправильним. Маска зламана, менш детальна або неправильно вирівняна.
Невідповідність виразів обличчя. Вони чужорідні, риси неприродні, розмиті чи непомітні.
Суперсила
Розрізняти діпфейки у світі постправди та маніпуляцій — справжнісінька суперсила. Щоправда, це не панацея: навіть найбільш натреноване око може одного разу зіштовхнутися з діпфейком, до якого важко причепитися. Але ці тренування точно не будуть зайвими. У процесі розвиватиметься й інша частина мисленнєвого та аналітичного апарату. Це означає, що прискіпливі та натреновані зануди шукатимуть правду та ніколи не віритимуть одному джерелу, навіть якщо воно виглядає правдоподібно.
