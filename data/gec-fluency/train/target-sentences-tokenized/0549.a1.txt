" Філософсько - етичні проблеми у сфері штучного інтелекту "
Питання життя та смерті — одвічне філософське питання , яке більшість людей вирішує по-своєму .
А що коли я скажу , що це питання потребує негайного й одноголосного рішення ?
За останні кілька років прогрес у сфері штучного інтелекту та машинного навчання зробив величезний крок уперед .
Більшість людей вже звикла до смартових речей у нашому житті — фітнес - трекерів з вимірюванням пульсу , кардіограми та багатьох біометричних показників , смартфонів з розблокуванням сітківкою чи власним обличчям , для багатьох навіть роботи доставки " Амазон " на вулицях Кремнієвої долини — звичайна річ .
Насправді процес сягає великих проривів у медицині .
Зараз системи розпізнавання зображень здатні визначити наявність певних видів раку чи наявність пневмонії краще за кваліфікованих лікарів .
Більшість із нас не задумується про етичні та філософські проблеми , з якими стикаються спеціалісти з штучного інтелекту , які розробляють технологічні рішення .
У серпні цього року науковий співробітник із комп’ютерного зору та робототехніки Кембриджського університету Алекс Кендал опублікував роздум ” Let`s talk about Artificial intelligence ” , де розглянув конкретні етичні проблеми спеціалістів із машинного навчання .
Три ключові проблеми , які він розглянув , це : довіра , чесність та справедливість .
Якщо чесність вимагає в основному легкого інтерпретування рішень , тобто вміння алгоритмом надати певні суттєві причини для деякого рішення , то з довірою та справедливістю все набагато складніше .
Справедливість .
Розглянемо доволі простий приклад .
Згідно з TrafficSTATS study by CMU for AAA ( 2007 ) чоловіки мають на 77 % вищий ризик померти в автомобільній аварії , ніж жінка .
Тобто якщо подібні дані включають у модель , яка визначає ймовірність потрапити в аварію та вартість страхового полісу , вона матиме кращу точність , тобто буде справедливішою до реальної статистики .
Проте , згідно з рішенням Європейського суду справедливості у 2011 році , стать не може бути врахована у вартість страхового полісу як фактор ризику , бо вважатиметься дискримінацією .
Іншими виявленими прикладами нечесних / необ’єктивних систем є : система розпізнавання голосу компанії Google систематично краще справляється з чоловічим голосом , ніж із жіночим , система підрахунку ризику повторного правопорушення необ’єктивна щодо афроамериканців .
На жаль , системи штучного інтелекту мають властивість наслідувати упередженість від людей .
Вирішення цієї проблеми полягає в використанні якісніших датасетів для кращого вивчення маленьких ( рідкісних ) класів , збільшенні якості методів збору та обробки даних , для зменшення упередженості даних .
Якщо зі справедливістю кроки доволі технічні , то з довірою все набагато складніше .
Критично важливим є те , що користувачі довіряють системам штучного інтелекту .
Якщо система не має належного рівня довіри , то ми навряд її використовуватимемо .
Для побудови безпечних систем машинного навчання потрібно показати високу точність алгоритму , будувати алгоритми , які не тільки мають високу точність розв'язання завдання , а й уміють визначати неточність своїх передбачень і розуміють , що є речі , їм невідомі ( наприклад , використовувати Баєсівські моделі глибокого навчання ) .
Повертаючись до проблеми життя та смерті .
У 2015 році видання " MIT Technology Review " опублікувало на тему “ Why Self-Driving Cars Must Be Programmed to Kill ” , у якій представлено високо ймовірну ситуацію на дорозі , де хтось з великою ймовірністю загине , лишається тільки обрати , хто саме .
Саме тому на цей момент ми не маємо повністю самокерованих машин .
Більшість цих проблем зараз лягає на плечі розробників , проте ми не можемо точно сказати , чи їхні рішення будуть справедливими , оскільки люди все ще лишаються людьми .
Очевидно тільки одне , на цей момент спеціалісти зі штучного інтелекту можуть вплинути на тільки на технологічну сферу , а також на етику та філософію .
Всі описані вище проблеми потребують найшвидшого вирішення , інакше штучний інтелект може не виправдати сподівань людей і настане наступна технологічна зима .
