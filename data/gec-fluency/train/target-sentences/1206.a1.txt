У цій доповіді ми розглянемо останні тренди в опрацюванні мовлення (speech processing).
Головним з них є transfer learning.
При transfer learning ми спершу претренуємо модель на задачі, яка не обов'язково нас цікавить, але для якої є багато даних.
Потім ми беремо цю претреновану модель та донавчаємо (fine-tuning) її на задачі, яка справді нас цікавить, але для якої зазвичай  є мало даних.
У текстовому NLP використовуються великі обсяги нерозміченого тексту для претренування мовних моделей, таких як GPT-2 та BERT.
Для опрацювання мовлення ми можемо подібним чином використати нерозмічені звукові дані — подкасти, відео з YouTube, аудіокнижки тощо.
У текстовому NLP нашим завданням було або вгадувати наступне слово (GPT-3), або замасковані слова (BERT).
Задача для претренінгу в speech processing є дуже подібною.
У нас тепер немає слів (токенів), але є звукові фрейми.
Ми можемо або передбачати, які фрейми будуть іти за попередніми, або закривати маскою частину фреймів та намагатися відтворити їх з контексту.
Ці ідеї, у спрощеному вигляді, лежать в основі Contrastive predicting coding (CPC), wav2vec 2.0 та HuBERT.
Деталі реалізації відрізняються для всіх цих моделей.
Але для всіх них є спільний "інтерфейс": на вхід подається звуковий сигнал (waveform), на виході маємо послідовність векторів, які цей сигнал кодують.
Кожен вектор відповідає маленькому часовому фрагменту (10-20 мс) та містить у собі більше семантичної інформації, ніж просто вейвформа чи Mel-спектрограма.
З цих моделей найновішою та емпірично найкращою є HuBERT від Facebook AI Research.
Розгляньмо її трохи детальніше.
