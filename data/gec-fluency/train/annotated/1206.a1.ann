У цій доповіді ми розглянемо останні тренди в опрацюванні мовлення (speech processing). Головним з них є transfer learning. При transfer learning ми спершу претренуємо модель на задачі, яка не обов'язково нас цікавить, але для якої є багато даних. Потім ми беремо цю претреновану модель та донавчаємо (fine-tuning) її на задачі, яка справді нас цікавить, але для якої зазвичай  є мало даних.

У текстовому NLP використовуються великі обсяги нерозміченого тексту для претренування мовних моделей, таких як GPT-2 та BERT. Для опрацювання мовлення ми можемо подібним чином використати нерозмічені звукові дані {--=>—:::error_type=Punctuation} подкасти, відео з YouTube, аудіокнижки тощо.

У текстовому NLP {нашою=>нашим:::error_type=G/Gender} {задачею=>завданням:::error_type=F/Calque} було або вгадувати наступне слово (GPT-3), або замасковані слова (BERT).{  => :::error_type=Punctuation}Задача для претренінгу в speech processing є дуже подібною. У нас тепер немає слів (токенів), але є звукові фрейми. Ми можемо або передбачати, які фрейми будуть {слідувати=>іти:::error_type=F/Style} за попередніми, або закривати маскою частину фреймів та намагатися відтворити їх з контексту. Ці ідеї, у {спрощенному=>спрощеному:::error_type=Spelling} вигляді, лежать в основі Contrastive predicting coding (CPC), wav2vec 2.0 та HuBERT.

Деталі реалізації відрізняються для всіх цих моделей. Але для всіх них є спільний "інтерфейс": на вхід подається звуковий сигнал (waveform), на виході маємо послідовність векторів, які цей сигнал кодують. Кожен вектор відповідає маленькому часовому фрагменту (10-20 мс) та містить {в=>у:::error_type=Spelling} собі більше семантичної інформації, ніж просто вейвформа чи Mel-спектрограма.
З цих моделей найновішою та емпірично найкращою є HuBERT від Facebook AI Research. Розгляньмо її трохи{=> детальніше:::error_type=F/PoorFlow}{ =>:::error_type=Punctuation}{більш детально=>:::error_type=F/PoorFlow}.
